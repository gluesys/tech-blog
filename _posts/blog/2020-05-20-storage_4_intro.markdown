---
layout:     post
title:      "스토리지 기초 지식 4편: 중복제거"
date:       2020-05-20
author:     박 주형 (jhpark@gluesys.com)
categories: blog
tags:       스토리지 데이터 중복제거 압축율 해시 백업 아카이브 deduplication data-reduction
cover:      "/assets/storage_rack.jpg"
main:       "/assets/storage_rack.jpg"
---

우리의 뇌는 일상생활에서 수집한 정보를 선별하고 정리하는 과정을 거쳐 최종적으로 장기 기억에 저장합니다. 뇌는 한 번에 기억할 수 있는 양이 한정되어 있어 이러한 최적화 과정을 거치는데요, 스토리지도 이처럼 최적화할 방법이 있습니다. 예를 들어 스토리지에 A라는 데이터가 저장된 상태에서 조금 수정된 A’라는 데이터가 들어올 경우, 이전에 저장된 데이터 A와 중복되는 부분의 데이터를 분석해 수정된 부분만 저장할 수 있는데, 이러한 기술을 **데이터 중복제거(data deduplication)**라고 합니다.  

&nbsp;

## 중복제거란

&nbsp;

중복제거는 쉽게 말하자면 중복된 데이터를 찾아 제거하는 것을 의미합니다. 식당에 단체로 가서 음식 주문을 하면 사람마다 무엇을 먹을지 메모지로 받아 적는 경우가 있는데요, 이때 중복되는 메뉴가 있으면 하나하나 적지 않고 옆에 개수를 적어 메모지의 공간과 수고를 덜곤 합니다. 이처럼 스토리지의 중복제거도 데이터의 크기와 전송속도를 줄이기 위해 중복되는 데이터를 제거하거나 저장하지 않을 수 있습니다.  

중복제거 작업은 주로 소프트웨어 레벨에서 이루어지며, 중복되는 데이터를 파악해 처음 저장된 데이터만을 남겨두는 방식으로 진행됩니다. 중복되는 데이터가 있는 자리에는 원본 데이터의 위치만 남겨둡니다. 이렇게 중복되는 부분을 파악하기 위해 주로 블록(block) 또는 청크(chunk)라는 하나의 데이터 덩어리로 나누고, 각 블록에 고유의 해시(hash)값을 부여해 구분합니다. 이때 같은 해시값을 가진 블록은 중복되는 데이터로 인식합니다. 데이터의 중복 여부는 고유의 해시 값 구분을 통해 이루어지는데, 다른 내용의 블록에 같은 해시 값이 생성되어 해시 값 충돌로 데이터의 손상을 발생시킬 가능성이 있다고 합니다. 하지만 해시 값 중복 생성은 대한민국에서 로또를 연속으로 4번 당첨될 확률 보다 낮기 때문에 (SHA-1 방식 기준, 16 PB 시스템 내에서 1/10<sup>24</sup>의 확률) IT 인프라를 운용하는 입장에서는 여타 데이터 손실 리스크에 비하면 거의 없는 경우나 마찬가지입니다.  

&nbsp;  

![Alt text](/assets/dedup_intro.png){: width="800"}

<center>&#60;중복제거의 기본 개념&#62;</center>

&nbsp;

## 중복제거의 분류

&nbsp;

중복제거 기능을 사용하는 가장 큰 이유 중 하나는 바로 비용 절감입니다. 중복제거를 통해 저장공간을 크게 확보할 수 있어 용량 증설 비용을 줄일 수 있습니다. 중복제거는 인프라의 형태와 규모, 워크로드의 부하 수준 등에 따라 적합한 중복제거 방식이 다를 수 있습니다. 중복제거 도입 방식에 따라 최적의 성능 및 비용 효율을 낼 수 있기 때문입니다.  

### 위치

여러 워크스테이션에서 한 작업을 하나의 공유 스토리지에 모으거나 주 스토리지와 백업 스토리지를 운용하는 경우, 중복제거를 클라이언트 측(소스, source)에서 진행할지, 데이터 전송 대상(타겟, target)에서 진행할지를 결정해야 합니다. 더불어 상황에 맞추어서 두 가지 방식을 전부 도입하는 것도 방법이라 할 수 있습니다.  

**소스 중복제거(source-based deduplication)**는 소스 측에서 중복제거를 진행한 후 타겟에 전송하는 방식을 말합니다. 이 방식의 경우, 타겟으로 전송되는 데이터양을 크게 감소시킬 수 있고, 전반적인 백업 속도를 향상시킬 수 있습니다. 다만 중복제거를 위한 해시 생성 작업으로 인해 소스 측 CPU 리소스가 소모되고, 데이터 복구 속도가 느린 점이 있습니다. 소스 중복제거는 대역폭을 절약하여 낮은 대역폭 환경에서의 원격 백업에 특화되어 있고, SW 백업 에이전트만 설치하기 때문에 구축이 간단해 소규모 원격 사무소에 적합한 방식입니다. 부가적으로 백업 장치의 용량과 비용 효율 확보에 적합합니다.  

**타겟 중복제거(target-based deduplication)**는 타겟 스토리지에서 진행되는 중복제거를 말합니다. 이 방식은 소스에 상관없이 타겟마다 같은 소프트웨어를 사용할 수 있고, 대부분 백업 소프트웨어와 호환된다는 장점이 있습니다. 무엇보다 소스에 리소스 부하 없이 진행되어 서비스 운용이나 복구 속도에 지장을 주지 않습니다. 다만, 소스에서 모든 데이터를 그대로 가져오기 때문에 소스 중복제거보다 리소스 활용이 많은 점이 있습니다. 해당 방식은 중복제거 작업보다 업로드 시 발생하는 리소스 비용이 낮은 경우에 특화되어 있어 소스 측 성능을 확보하기에 적합합니다. 소스 중복제거에 비해 오래된 기술로 안정적이라 대규모 데이터베이스나 일일 데이터 변경 빈도가 높은 데이터베이스 구축환경에 도입하기 적합합니다.  

&nbsp;

### 시기

중복제거는 저장장치에 기록하기 전(인라인, inline)에 진행하거나 기록 후(후처리, post-process)에 진행하는 방법이 있습니다.  

**인라인 중복제거(inline deduplication)**는 데이터를 저장장치에 쓰기 작업을 진행하기 전에 중복제거를 진행하는 방법을 말합니다. 중복제거 된 데이터가 저장되기 때문에 저장 공간을 적게 할당이 가능하며, 백업 시 중복되는 트래픽을 덜어내기 때문에 네트워크 병목과 디스크 부하를 낮출 수 있는 장점이 있습니다. 하지만 중복제거 과정이 즉석에서 진행되는 점이 있고, 데이터 복구 시 중복제거 된 데이터의 복원 작업으로 리소스와 시간이 소요될 수 있습니다. 이 때문에 주 스토리지보다는 전용 백업 어플라이언스에서 자주 사용됩니다.  

**후처리 중복제거(post-process deduplication)**는 반대로 저장장치의 임시 영역(랜딩 존)에 데이터를 전부 받은 후 중복제거를 진행합니다. 무엇보다 워크로드가 적은 시간대에 중복제거 작업을 예약해서 진행할 수 있어 스토리지 리소스를 아낄 수 있습니다. 또한 인라인 중복제거와는 달리 데이터 복구 시 임시 영역에 복구가 필요한 데이터가 있는 경우 적은 시간에 복구를 할 수 있습니다. 다만 임시 영역을 사용하기 때문에 충분한 용량을 갖추어야 하며, 복제 작업 시 중복제거 작업이 완료될 때까지 복제가 지연됩니다. 이처럼 스토리지 리소스 활용이 용이하기 때문에 주 저장장치에 활용되는 경향이 있습니다.  

&nbsp;

### 방식

데이터를 블록으로 나누어 중복되는 블록을 검출할 시 블록의 크기를 고정(fixed block)해서 나누거나 가변적(variable block)으로 나누는 방식을 취해 필요에 따라 중복제거 효율을 높일 수 있습니다.  

**고정 블록 중복제거(fixed block deduplication)**는 데이터를 고정된 블록 크기로 분류해 중복제거를 진행하는 것을 말합니다. 이 방식은 고정된 블록 크기로 단순한 해시 알고리즘을 쓰기 때문에 중복제거 속도가 빠르고 CPU 부하가 적습니다. 다만 모든 데이터 유형에 고정된 크기로 중복을 제거하기 때문에 중복제거율이 떨어지는 편입니다. CPU 부하가 적은 특성으로 인해 주 스토리지에 사용하기 적합합니다.  

**가변 블록 중복제거(variable block deduplication)**는 데이터 유형에 맞게 블록 크기를 자동으로 나누어 분류해 중복제거를 진행하는 것을 말합니다. 블록 크기를 유연하게 조정할 수 있어 데이터 유형이 다양한 경우에 적합하며, 매우 높은 중복제거 효율을 보일 수 있습니다. 다만 블록 크기 파악 및 해시 처리 등으로 CPU 부하가 높아 워크로드가 빠듯한 주 스토리지에는 적합하지 않고 백업용 스토리지에 많이 쓰입니다.  

&nbsp;

### 범위

데이터의 중복을 단일 장비 내(local)에서만 찾을지, 복수의 장비(global)에서 찾을지에 따라 중복 비율이 다를 수 있습니다.  

**글로벌 중복제거(global deduplication)**는 하나 이상의 백업 스토리지나 클라이언트 내 데이터를 대상으로 중복제거 하는 것을 말합니다. 각각 장비에 중복되는 데이터를 색출하기 때문에 중복제거 비율이 매우 높게 나올 수 있으며, 같은 라이브러리 내에 저장된 여러 데이터 타입에 대한 데이터 유지 정책을 보다 유연하게 제공할 수 있습니다. 다만 저장된 데이터가 대용량이 아닌 이상 중복제거율이 높게 나오기 힘들고, 복제 없이 블록이 한 번만 저장되는 경우 데이터 보호에 취약할 수 있습니다. 원격 사무실을 둔 기업으로서 클라우드 백업 기능과 같이 쓰기 쉽습니다.  

**로컬 중복제거(local deduplication)**는 단순히 하나의 장비에서 국소적으로 중복제거를 하는 것을 말합니다. 다루는 데이터의 크기와 종류에 따라 글로벌 중복제거보다 낮은 중복제거율을 보입니다.  

&nbsp;  

![Alt text](/assets/dedup_comparison.png){: width="800"}

<center>&#60;주 스토리지와 백업 어플라이언스에서의 중복제거 타입&#62;</center>

&nbsp;

## 중복제거를 통한 변화

중복제거 기술의 보편화로 백업용 스토리지가 테이프에서 하드디스크 중심으로 전환하게 되었습니다. 테이프는 특유의 저가격과 안정성으로 백업이나 아카이브에 적합합니다. 디스크와 비교해 바이트 당 가격 경쟁력도 매우 뛰어난 편입니다. 하지만 디스크는 테이프에 비해 다중 동시 백업이 가능하다는 점, 장애 복구 시간이 짧다는 점 등의 장점이 있고, 무엇보다 중복제거를 통해 오프사이트 백업 및 복구가 압도적으로 편리해 하드디스크로 구성된 스토리지 사용이 월등히 증가하고 있습니다.  

또한 중복제거 기술은 주 스토리지와 백업 스토리지 사이의 다리 역할을 수행하게 되었습니다. 기존에 백업 스토리지는 미디어 서버가 백업 소프트웨어를 돌려 백업 전송을 조정하는 역할을 했습니다. 중복제거 기술의 등장으로 백업 스토리지뿐만 아니라 주 스토리지에서도 직접 백업 에이전트가 동작해 별도의 미디어 서버를 통할 필요가 없어졌습니다.  

&nbsp;

## 마치며

이전 권진영씨의 제 7회 난공불락 인프라 세미나 포스트에서 VDO의 중복제거를 소개하셨는데 이를 계기로 중복제거 기술의 기본적인 개념을 다루어 보았습니다. 최근 이더넷 속도, 스토리지 및 프로세서 기술의 발전으로 단순히 백업이나 아카이브 스토리지에서 쓰이는 것을 넘어서 주 스토리지, 퍼블릭 클라우드, 클라이언트 단에서도 중복제거가 사용되고 있습니다. 중복제거 기능은 널리 사용된 지 오래된 기술이지만 데이터 폭증과 다변화하는 IT 환경에 맞추어 꾸준히 진화해 나갈 것입니다.  

&nbsp;

## 참고

중복제거 개념: 
 * Xia, W., Jiang, H., Feng, D., Douglis, F., Shilane, P., Hua, Y., ... & Zhou, Y. (2016). A comprehensive study of the past, present, and future of data deduplication. Proceedings of the IEEE, 104(9), 1681-1710.
 * https://www.dynamicsolutions.com/assets/pdfs/How_DeDupe_Works.pdf

중복제거 동향: 
 * https://searchstorage.techtarget.com/tip/Understanding-data-deduplication-for-primary-storage
 * http://www.itworld.co.kr/news/111601
 * https://techbeacon.com/enterprise-it/8-deadly-misconceptions-about-data-deduplication

